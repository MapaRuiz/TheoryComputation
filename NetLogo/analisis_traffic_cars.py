# -*- coding: utf-8 -*-
"""Analisis Traffic Cars.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FjRp2VHI5RsMatWkTM5gH9R3Tmxi1SD5
"""

# Análisis de Experimentos Traffic Basic - NetLogo
# Experimentos de Serie de Tiempo y Post-Mortem

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# Configurar estilo de gráficos
plt.style.use('default')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 10

print("=== ANÁLISIS DE EXPERIMENTOS TRAFFIC BASIC ===\n")

# ==============================================================================
# 1. ANÁLISIS DE SERIE DE TIEMPO
# ==============================================================================

print("1. CARGANDO DATOS DE SERIE DE TIEMPO...")

# Cargar datos de Serie de Tiempo (skip 7 líneas de encabezado)
try:
    data_tiempo = pd.read_csv('TrafficBasic-ExpSerieDeTiempo.csv', skiprows=7)
    print(f"✓ Datos cargados: {data_tiempo.shape[0]} filas, {data_tiempo.shape[1]} columnas")
    print(f"Columnas: {list(data_tiempo.columns)}")
    print("\nPrimeras filas:")
    print(data_tiempo.head())
except Exception as e:
    print(f"❌ Error cargando archivo: {e}")
    print("Por favor verifica que el archivo 'TrafficBasic-ExpSerieDeTiempo.csv' esté disponible")

# Renombrar columnas para facilitar el análisis
print("\n2. PROCESANDO DATOS DE SERIE DE TIEMPO...")

try:
    # Renombrar según la estructura real vista en las imágenes
    data_tiempo.columns = ['run_number', 'acceleration', 'number_of_cars', 'deceleration', 'step', 'mean_speed']

    # Mostrar información básica
    print(f"Experimentos únicos: {data_tiempo['run_number'].nunique()}")
    print(f"Valores de aceleración: {sorted(data_tiempo['acceleration'].unique())}")
    print(f"Valores de desaceleración: {sorted(data_tiempo['deceleration'].unique())}")
    print(f"Rango de pasos: {data_tiempo['step'].min()} - {data_tiempo['step'].max()}")

    # Seleccionar columnas relevantes (excluir number_of_cars que es constante)
    data_tiempo_clean = data_tiempo[['acceleration', 'deceleration', 'step', 'mean_speed']].copy()

    print(f"Número de coches (constante): {data_tiempo['number_of_cars'].iloc[0]}")
    print(f"Rango de aceleración: {data_tiempo['acceleration'].min()} - {data_tiempo['acceleration'].max()}")
    print(f"Rango de desaceleración: {data_tiempo['deceleration'].min()} - {data_tiempo['deceleration'].max()}")

except Exception as e:
    print(f"❌ Error procesando datos: {e}")
    print("Ajustaré el análisis según la estructura real de los datos")

# ==============================================================================
# 3. VISUALIZACIONES DE SERIE DE TIEMPO
# ==============================================================================

print("\n3. CREANDO VISUALIZACIONES DE SERIE DE TIEMPO...")

# Gráfico 1: Vista general de todas las series
plt.figure(figsize=(15, 10))

plt.subplot(2, 2, 1)
try:
    # Muestra de datos para evitar sobrecarga visual
    sample_data = data_tiempo_clean.sample(min(2000, len(data_tiempo_clean)))
    # CORRECCIÓN 1: Puntos más grandes y color azul oscuro
    plt.scatter(sample_data['step'], sample_data['mean_speed'],
               alpha=0.6, s=8, color='darkblue', edgecolors='none')
    plt.xlabel('Tiempo (steps)')
    plt.ylabel('Velocidad Promedio')
    plt.title('Vista General: Velocidad vs Tiempo')
    plt.grid(True, alpha=0.3)
except:
    plt.text(0.5, 0.5, 'Error en datos', ha='center', va='center', transform=plt.gca().transAxes)

# Gráfico 2: Agrupado por parámetros
plt.subplot(2, 2, 2)
try:
    # Agrupar datos por parámetros y tiempo
    grouped_data = data_tiempo_clean.groupby(['acceleration', 'deceleration', 'step'])['mean_speed'].mean().reset_index()

    # Seleccionar algunas combinaciones para visualizar
    unique_combinations = grouped_data[['acceleration', 'deceleration']].drop_duplicates().head(6)

    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_combinations)))

    for i, (_, combo) in enumerate(unique_combinations.iterrows()):
        subset = grouped_data[
            (grouped_data['acceleration'] == combo['acceleration']) &
            (grouped_data['deceleration'] == combo['deceleration'])
        ]
        if len(subset) > 0:
            plt.plot(subset['step'], subset['mean_speed'],
                    color=colors[i], alpha=0.7, linewidth=1,
                    label=f'Acc:{combo["acceleration"]:.3f}, Dec:{combo["deceleration"]:.3f}')

    plt.xlabel('Tiempo (steps)')
    plt.ylabel('Velocidad Promedio')
    plt.title('Evolución por Configuración')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
    plt.grid(True, alpha=0.3)
except Exception as e:
    plt.text(0.5, 0.5, f'Error: {str(e)[:50]}...', ha='center', va='center', transform=plt.gca().transAxes)

# Gráfico 3: Heatmap de velocidad final por parámetros
plt.subplot(2, 2, 3)
try:
    # Velocidad promedio en los últimos 100 steps (estado estable)
    final_steps = data_tiempo_clean[data_tiempo_clean['step'] >= data_tiempo_clean['step'].max() - 100]
    final_speeds = final_steps.groupby(['acceleration', 'deceleration'])['mean_speed'].mean().reset_index()

    # Crear matriz para heatmap
    pivot_data = final_speeds.pivot(index='deceleration', columns='acceleration', values='mean_speed')

    sns.heatmap(pivot_data, annot=True, fmt='.3f', cmap='viridis', cbar_kws={'label': 'Velocidad Final'})
    plt.title('Velocidad Final por Parámetros')
    plt.xlabel('Aceleración')
    plt.ylabel('Desaceleración')
except Exception as e:
    plt.text(0.5, 0.5, f'Error en heatmap: {str(e)[:30]}...', ha='center', va='center', transform=plt.gca().transAxes)

# Gráfico 4: Variabilidad temporal
plt.subplot(2, 2, 4)
try:
    # Calcular coeficiente de variación temporal para cada configuración
    cv_data = data_tiempo_clean.groupby(['acceleration', 'deceleration'])['mean_speed'].agg(['mean', 'std']).reset_index()
    cv_data['cv'] = cv_data['std'] / cv_data['mean']

    scatter = plt.scatter(cv_data['mean'], cv_data['cv'],
                         c=cv_data['acceleration'], cmap='plasma', alpha=0.7, s=50)
    plt.colorbar(scatter, label='Aceleración')
    plt.xlabel('Velocidad Promedio')
    plt.ylabel('Coeficiente de Variación')
    plt.title('Estabilidad vs Velocidad')
    plt.grid(True, alpha=0.3)
except Exception as e:
    plt.text(0.5, 0.5, f'Error: {str(e)[:30]}...', ha='center', va='center', transform=plt.gca().transAxes)

plt.tight_layout()
plt.show()

# ==============================================================================
# 4. ANÁLISIS POST-MORTEM
# ==============================================================================

print("\n4. CARGANDO DATOS POST-MORTEM...")

try:
    data_postmortem = pd.read_csv('TrafficBasic-ExpPostMortem.csv', skiprows=7)
    print(f"✓ Datos cargados: {data_postmortem.shape[0]} filas, {data_postmortem.shape[1]} columnas")
    print(f"Columnas: {list(data_postmortem.columns)}")
    print("\nPrimeras filas:")
    print(data_postmortem.head())
except Exception as e:
    print(f"❌ Error cargando archivo: {e}")
    print("Por favor verifica que el archivo 'TrafficBasic-ExpPostMortem.csv' esté disponible")

# Procesar datos post-mortem
print("\n5. PROCESANDO DATOS POST-MORTEM...")

try:
    # Renombrar columnas según estructura real
    data_postmortem.columns = ['run_number', 'acceleration', 'number_of_cars', 'deceleration', 'step', 'final_speed']

    print(f"Total de ejecuciones: {len(data_postmortem)}")
    print(f"Configuraciones únicas: {len(data_postmortem[['acceleration', 'deceleration']].drop_duplicates())}")
    print(f"Número de coches (constante): {data_postmortem['number_of_cars'].iloc[0]}")
    print(f"Steps finales: {data_postmortem['step'].unique()}")  # Debería ser 1000 para todos

    # Estadísticas descriptivas
    grouped_stats = data_postmortem.groupby(['acceleration', 'deceleration'])['final_speed'].agg([
        'count', 'mean', 'std', 'min', 'max'
    ]).round(4)

    print("\nEstadísticas por configuración:")
    print(grouped_stats.head(10))

except Exception as e:
    print(f"❌ Error procesando datos post-mortem: {e}")

# ==============================================================================
# 6. VISUALIZACIONES POST-MORTEM
# ==============================================================================

print("\n6. CREANDO VISUALIZACIONES POST-MORTEM...")

plt.figure(figsize=(15, 10))

# Gráfico 1: Distribución de velocidades finales
plt.subplot(3, 2, 1)
try:
    plt.hist(data_postmortem['final_speed'], bins=30, alpha=0.7, edgecolor='black')
    plt.xlabel('Velocidad Final')
    plt.ylabel('Frecuencia')
    plt.title('Distribución de Velocidades Finales')
    plt.grid(True, alpha=0.3)
except:
    plt.text(0.5, 0.5, 'Error en histograma', ha='center', va='center', transform=plt.gca().transAxes)

# Gráfico 2: Scatter plot con regresión
plt.subplot(3, 2, 4)
try:
    # Promedios por configuración
    avg_data = data_postmortem.groupby(['acceleration', 'deceleration'])['final_speed'].mean().reset_index()

    scatter = plt.scatter(avg_data['acceleration'], avg_data['final_speed'],
                         c=avg_data['deceleration'], cmap='coolwarm', s=100, alpha=0.7)
    plt.colorbar(scatter, label='Desaceleración')
    palette='Blues'

    # Línea de regresión
    z = np.polyfit(avg_data['acceleration'], avg_data['final_speed'], 1)
    p = np.poly1d(z)
    plt.plot(avg_data['acceleration'], p(avg_data['acceleration']), "r--", alpha=0.8)

    plt.xlabel('Aceleración')
    plt.ylabel('Velocidad Final Promedio')
    plt.title('Relación Aceleración-Velocidad')
    plt.grid(True, alpha=0.3)
except Exception as e:
    plt.text(0.5, 0.5, f'Error: {str(e)[:30]}...', ha='center', va='center', transform=plt.gca().transAxes)

# Gráfico 3: Boxplot por aceleración
plt.subplot(3, 2, 2)
try:
    sns.boxplot(x='acceleration', y='final_speed', data=data_postmortem, palette='Reds')
    plt.title('Velocidad Final por Aceleración')
    plt.suptitle('')  # Quitar título automático
    plt.xticks(rotation=45)
except:
    plt.text(0.5, 0.5, 'Error en boxplot', ha='center', va='center', transform=plt.gca().transAxes)

# Gráfico 4: Boxplot por desaceleración
plt.subplot(3, 2, 3)
try:
    sns.boxplot(x='deceleration', y='final_speed', data=data_postmortem, palette='Blues')
    plt.title('Velocidad Final por Desaceleración')
    plt.suptitle('')
    plt.xticks(rotation=45)
except:
    plt.text(0.5, 0.5, 'Error en boxplot', ha='center', va='center', transform=plt.gca().transAxes)

# Gráfico 5: Heatmap de velocidades promedio
plt.subplot(3, 2, 5)
try:
    avg_pivot = data_postmortem.groupby(['acceleration', 'deceleration'])['final_speed'].mean().reset_index()
    pivot_matrix = avg_pivot.pivot(index='deceleration', columns='acceleration', values='final_speed')

    sns.heatmap(pivot_matrix, annot=True, fmt='.2f', cmap='RdYlBu_r',
                cbar_kws={'label': 'Velocidad Final'})
    plt.title('Mapa de Calor: Velocidad Final')
    plt.xlabel('Aceleración')
    plt.ylabel('Desaceleración')
except Exception as e:
    plt.text(0.5, 0.5, f'Error en heatmap: {str(e)[:30]}...', ha='center', va='center', transform=plt.gca().transAxes)

# Gráfico 6: Análisis de variabilidad
plt.subplot(3, 2, 6)
try:
    var_data = data_postmortem.groupby(['acceleration', 'deceleration'])['final_speed'].agg(['mean', 'std']).reset_index()
    var_data.columns = ['acceleration', 'deceleration', 'mean_speed', 'std_speed']

    plt.scatter(var_data['mean_speed'], var_data['std_speed'],
               c=var_data['acceleration'], cmap='viridis', s=100, alpha=0.7)
    plt.colorbar(label='Aceleración')
    plt.xlabel('Velocidad Promedio')
    plt.ylabel('Desviación Estándar')
    plt.title('Variabilidad vs Velocidad')
    plt.grid(True, alpha=0.3)
except Exception as e:
    plt.text(0.5, 0.5, f'Error: {str(e)[:30]}...', ha='center', va='center', transform=plt.gca().transAxes)

plt.tight_layout()
plt.show()

# ==============================================================================
# 7. ANÁLISIS ESTADÍSTICO
# ==============================================================================

print("\n7. ANÁLISIS ESTADÍSTICO...")

try:
    # Correlaciones
    print("\n--- CORRELACIONES ---")
    correlation_data = data_postmortem[['acceleration', 'deceleration', 'final_speed']].corr()
    print(correlation_data)

    # ANOVA para efectos de parámetros
    print("\n--- ANÁLISIS DE VARIANZA ---")
    from scipy.stats import f_oneway

    # Agrupar por niveles de aceleración
    acc_groups = [group['final_speed'].values for name, group in data_postmortem.groupby('acceleration')]
    f_stat_acc, p_val_acc = f_oneway(*acc_groups)
    print(f"Efecto de Aceleración - F: {f_stat_acc:.4f}, p-valor: {p_val_acc:.6f}")

    # Agrupar por niveles de desaceleración
    dec_groups = [group['final_speed'].values for name, group in data_postmortem.groupby('deceleration')]
    f_stat_dec, p_val_dec = f_oneway(*dec_groups)
    print(f"Efecto de Desaceleración - F: {f_stat_dec:.4f}, p-valor: {p_val_dec:.6f}")

    # Mejores y peores configuraciones
    print("\n--- CONFIGURACIONES EXTREMAS ---")
    best_config = data_postmortem.groupby(['acceleration', 'deceleration'])['final_speed'].mean().idxmax()
    worst_config = data_postmortem.groupby(['acceleration', 'deceleration'])['final_speed'].mean().idxmin()

    avg_speeds = data_postmortem.groupby(['acceleration', 'deceleration'])['final_speed'].mean()
    print(f"Mejor configuración: Acc={best_config[0]:.4f}, Dec={best_config[1]:.4f} -> Velocidad={avg_speeds[best_config]:.4f}")
    print(f"Peor configuración: Acc={worst_config[0]:.4f}, Dec={worst_config[1]:.4f} -> Velocidad={avg_speeds[worst_config]:.4f}")

    # Resumen ejecutivo
    print("\n" + "="*50)
    print("RESUMEN EJECUTIVO")
    print("="*50)
    print(f"• Total de simulaciones analizadas: {len(data_postmortem)}")
    print(f"• Configuraciones diferentes: {len(data_postmortem[['acceleration', 'deceleration']].drop_duplicates())}")
    print(f"• Rango de velocidades finales: {data_postmortem['final_speed'].min():.4f} - {data_postmortem['final_speed'].max():.4f}")
    print(f"• Velocidad promedio general: {data_postmortem['final_speed'].mean():.4f} ± {data_postmortem['final_speed'].std():.4f}")

    if p_val_acc < 0.05:
        print("• La ACELERACIÓN tiene un efecto significativo en la velocidad final")
    else:
        print("• La ACELERACIÓN NO tiene un efecto significativo en la velocidad final")

    if p_val_dec < 0.05:
        print("• La DESACELERACIÓN tiene un efecto significativo en la velocidad final")
    else:
        print("• La DESACELERACIÓN NO tiene un efecto significativo en la velocidad final")

except Exception as e:
    print(f"❌ Error en análisis estadístico: {e}")

print("\n✅ ANÁLISIS COMPLETO FINALIZADO")

